
# load libraries
from nltk.tokenize import word_tokenize, sent_tokenize

# create text
string = "The science of today is the technology of tomorrow. Tomorrow is today."

# tokenize the words
word_tokenize(string)

# tokenize sentences
sent_tokenize(string)
